import os
import librosa
import librosa.display
import matplotlib.pyplot as plt
import sounddevice as sd
import soundfile as sf
import cv2
import numpy as np
from tensorflow.keras.models import load_model
from datetime import datetime
from tqdm import tqdm

# ========== CONFIGURA√á√ïES ==========
base_dir = '/Users/vitorwolffbordignon/Documents/projetos/speaker-identifier/LibriSpeech/dev-clean'
temp_img = 'temp.png'
sample_rate = 16000
duration = 5  # segundos de grava√ß√£o
n_mfcc = 20
n_frames_pad = 130
img_height, img_width = 256, 256
modelo_path = '/Users/vitorwolffbordignon/Documents/projetos/speaker-identifier/vwb-tests/modelo_identificador_vitor.h5'
silence_threshold = 0.01
# ===================================

# üßë Perguntar quem est√° falando
resposta = input("üë§ √â o Vitor falando? (s/n): ").strip().lower()
if resposta == 's':
    speaker_name = 'vwb-flac'
else:
    speaker_name = input("üìù Digite o nome da pessoa que est√° falando (ex: maria, jose): ").strip()
    speaker_name = speaker_name.replace(' ', '_').lower()

# Criar diret√≥rio se n√£o existir
speaker_dir = os.path.join(base_dir, speaker_name)
os.makedirs(speaker_dir, exist_ok=True)

# üéôÔ∏è Nome do arquivo
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
flac_filename = f"{speaker_name}_{timestamp}.flac"
flac_path = os.path.join(speaker_dir, flac_filename)

# üéôÔ∏è Gravar √°udio com contador
print("üéôÔ∏è Gravando... fale agora.")
recording = np.zeros((int(duration * sample_rate), 1), dtype='float32')
stream = sd.InputStream(samplerate=sample_rate, channels=1, dtype='float32')

with stream:
    for i in tqdm(range(duration), desc="‚è≥ Tempo restante"):
        frames = stream.read(sample_rate)[0]
        recording[i * sample_rate:(i + 1) * sample_rate] = frames
        rms = np.sqrt(np.mean(frames**2))
        if rms > silence_threshold:
            print("üéß Detec√ß√£o de som...")
        else:
            print("ü§´ Sil√™ncio detectado.")

# üíæ Salvar como FLAC
sf.write(flac_path, recording, sample_rate, format='FLAC')
print(f"‚úÖ √Åudio salvo como: {flac_path}")

# üéß Processar o √°udio para gerar imagem MFCC
y, sr = librosa.load(flac_path, sr=sample_rate)
y, _ = librosa.effects.trim(y, top_db=20)
mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
mfccs = librosa.util.fix_length(mfccs, size=n_frames_pad, axis=1)

# üñºÔ∏è Gerar imagem MFCC
fig = plt.figure(figsize=(2.56, 2.56), dpi=100)
ax = plt.Axes(fig, [0., 0., 1., 1.])
ax.set_axis_off()
fig.add_axes(ax)
librosa.display.specshow(mfccs, sr=sr, ax=ax)
plt.savefig(temp_img, bbox_inches='tight', pad_inches=0)
plt.close(fig)
print(f"üì∑ Imagem MFCC salva como: {temp_img}")

# üì∑ Preparar imagem para o modelo
img = cv2.imread(temp_img, cv2.IMREAD_GRAYSCALE)
img = cv2.resize(img, (img_width, img_height))
img = img.reshape((1, img_height, img_width, 1)).astype("float32") / 255.0

# ü§ñ Classifica√ß√£o com modelo
model = load_model(modelo_path)
pred = model.predict(img, verbose=0)[0][0]

# üìä Mostrar resultado
if pred >= 0.5:
    print(f"‚úÖ Modelo diz: √â o Vitor (confian√ßa: {pred:.2f})")
else:
    print(f"‚ùå Modelo diz: N√£o √© o Vitor (confian√ßa: {1 - pred:.2f})")
